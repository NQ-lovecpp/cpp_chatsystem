{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handoff 与 Input Filter 示例\n",
        "\n",
        "本 Notebook 演示 OpenAI Agents SDK 的 **Handoff（任务转移）** 机制，以及如何通过 **input_filter** 在转移时过滤对话历史。\n",
        "\n",
        "## 工作流程概览\n",
        "\n",
        "1. **first_agent**：通用助手，带有 `random_number_tool`\n",
        "2. **second_agent**：主入口，当用户说西班牙语时 handoff 到 Spanish Assistant\n",
        "3. **spanish_agent**：仅用西班牙语回复的助手\n",
        "\n",
        "当 handoff 发生时，`spanish_handoff_message_filter` 会：\n",
        "- 移除所有工具相关消息（function_call、tool_output 等）\n",
        "- 移除历史中的前两条消息（演示用）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 导入与定义"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "from agents import Agent, HandoffInputData, Runner, function_tool, handoff, trace\n",
        "from agents.extensions import handoff_filters\n",
        "from agents.models import is_gpt_5_default\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def random_number_tool(max: int) -> int:\n",
        "    \"\"\"Return a random integer between 0 and the given maximum.\"\"\"\n",
        "    return random.randint(0, max)\n",
        "\n",
        "\n",
        "def spanish_handoff_message_filter(handoff_message_data: HandoffInputData) -> HandoffInputData:\n",
        "    if is_gpt_5_default():\n",
        "        print(\"gpt-5 is enabled, so we're not filtering the input history\")\n",
        "        return HandoffInputData(\n",
        "            input_history=handoff_message_data.input_history,\n",
        "            pre_handoff_items=tuple(handoff_message_data.pre_handoff_items),\n",
        "            new_items=tuple(handoff_message_data.new_items),\n",
        "        )\n",
        "\n",
        "    # 移除所有工具相关消息\n",
        "    handoff_message_data = handoff_filters.remove_all_tools(handoff_message_data)\n",
        "\n",
        "    # 移除历史中的前两条（演示用）\n",
        "    history = (\n",
        "        tuple(handoff_message_data.input_history[2:])\n",
        "        if isinstance(handoff_message_data.input_history, tuple)\n",
        "        else handoff_message_data.input_history\n",
        "    )\n",
        "\n",
        "    return HandoffInputData(\n",
        "        input_history=history,\n",
        "        pre_handoff_items=tuple(handoff_message_data.pre_handoff_items),\n",
        "        new_items=tuple(handoff_message_data.new_items),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义三个 Agent\n",
        "first_agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"Be extremely concise.\",\n",
        "    tools=[random_number_tool],\n",
        ")\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish Assistant\",\n",
        "    instructions=\"You only speak Spanish and are extremely concise.\",\n",
        "    handoff_description=\"A Spanish-speaking assistant.\",\n",
        ")\n",
        "\n",
        "second_agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=(\n",
        "        \"Be a helpful assistant. If the user speaks Spanish, handoff to the Spanish assistant.\"\n",
        "    ),\n",
        "    handoffs=[handoff(spanish_agent, input_filter=spanish_handoff_message_filter)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Agent 结构可视化\n",
        "\n",
        "使用 SDK 的 `draw_graph` 可视化 Agent 与 Handoff 关系。\n",
        "\n",
        "**依赖安装（需两步）：**\n",
        "1. Python 包：`pip install \"openai-agents[viz]\"`\n",
        "2. **系统 Graphviz**（`dot` 可执行文件）：\n",
        "   - Ubuntu/Debian: `sudo apt-get install graphviz`\n",
        "   - macOS: `brew install graphviz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "17646d76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== first_agent（带 random_number_tool）===\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from agents.extensions.visualization import draw_graph\n",
        "    print(\"=== first_agent（带 random_number_tool）===\")\n",
        "    draw_graph(first_agent, filename=\"first_agent.png\")\n",
        "except ImportError as e:\n",
        "    print(\"可视化需要安装: pip install \\\"openai-agents[viz]\\\"\")\n",
        "    print(f\"错误: {e}\")\n",
        "except Exception as e:\n",
        "    if type(e).__name__ == \"ExecutableNotFound\":\n",
        "        print(\"系统未安装 Graphviz，请执行: sudo apt-get install graphviz  (Ubuntu/Debian)\")\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ecac4dc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== second_agent（Handoff 到 Spanish Assistant）===\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from agents.extensions.visualization import draw_graph\n",
        "    print(\"=== second_agent（Handoff 到 Spanish Assistant）===\")\n",
        "    draw_graph(second_agent, filename=\"second_agent\")\n",
        "except ImportError as e:\n",
        "    print(\"可视化需要安装: pip install \\\"openai-agents[viz]\\\"\")\n",
        "    print(f\"错误: {e}\")\n",
        "except Exception as e:\n",
        "    if type(e).__name__ == \"ExecutableNotFound\":\n",
        "        print(\"系统未安装 Graphviz，请执行: sudo apt-get install graphviz  (Ubuntu/Debian)\")\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可选：保存图为 PNG 文件\n",
        "# draw_graph(second_agent, filename=\"handoff_graph\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 运行 Handoff 工作流\n",
        "\n",
        "执行完整对话流程，Step 4 会触发 handoff 到 Spanish Assistant。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "Error getting response: Request timed out.. (request_id: None)\n",
            "Error getting response; filtered.input=[{'content': 'Hi, my name is Sora.', 'role': 'user'}]\n"
          ]
        },
        {
          "ename": "APITimeoutError",
          "evalue": "Request timed out.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_transports/default.py:394\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 394\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_async/connection_pool.py:256\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_async/connection_pool.py:236\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_async/connection.py:101\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_async/connection.py:78\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(request)\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_async/connection.py:124\u001b[0m, in \u001b[0;36mAsyncHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_backends/auto.py:31\u001b[0m, in \u001b[0;36mAutoBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_backend()\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\n\u001b[1;32m     32\u001b[0m     host,\n\u001b[1;32m     33\u001b[0m     port,\n\u001b[1;32m     34\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m     35\u001b[0m     local_address\u001b[38;5;241m=\u001b[39mlocal_address,\n\u001b[1;32m     36\u001b[0m     socket_options\u001b[38;5;241m=\u001b[39msocket_options,\n\u001b[1;32m     37\u001b[0m )\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_backends/anyio.py:122\u001b[0m, in \u001b[0;36mAnyIOBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n\u001b[0;32m--> 122\u001b[0m             stream\u001b[38;5;241m.\u001b[39m_raw_socket\u001b[38;5;241m.\u001b[39msetsockopt(\u001b[38;5;241m*\u001b[39moption)  \u001b[38;5;66;03m# type: ignore[attr-defined] # pragma: no cover\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AnyIOStream(stream)\n",
            "File \u001b[0;32m/usr/lib/python3.9/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mConnectTimeout\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/openai/_base_client.py:1604\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1604\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1605\u001b[0m         request,\n\u001b[1;32m   1606\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1608\u001b[0m     )\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_client.py:1629\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1627\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1629\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1630\u001b[0m     request,\n\u001b[1;32m   1631\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1632\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1633\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1634\u001b[0m )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_client.py:1657\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1658\u001b[0m         request,\n\u001b[1;32m   1659\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1660\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1661\u001b[0m     )\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_client.py:1694\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_client.py:1730\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1730\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_transports/default.py:394\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 394\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
            "File \u001b[0;32m/usr/lib/python3.9/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mConnectTimeout\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace(workflow_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandoff message filter\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Step 1: 发送第一条消息\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(first_agent, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi, my name is Sora.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore[top-level-await]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep 1 done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: 请求生成随机数\u001b[39;00m\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/run.py:219\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, error_handlers, previous_response_id, auto_previous_response_id, conversation_id, session)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03mRun a workflow starting at the given agent.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    type of the output.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m runner \u001b[38;5;241m=\u001b[39m DEFAULT_AGENT_RUNNER\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    220\u001b[0m     starting_agent,\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    222\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    223\u001b[0m     max_turns\u001b[38;5;241m=\u001b[39mmax_turns,\n\u001b[1;32m    224\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    225\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    226\u001b[0m     error_handlers\u001b[38;5;241m=\u001b[39merror_handlers,\n\u001b[1;32m    227\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    228\u001b[0m     auto_previous_response_id\u001b[38;5;241m=\u001b[39mauto_previous_response_id,\n\u001b[1;32m    229\u001b[0m     conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m    230\u001b[0m     session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    231\u001b[0m )\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/run.py:1027\u001b[0m, in \u001b[0;36mAgentRunner.run\u001b[0;34m(self, starting_agent, input, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1027\u001b[0m     turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m model_task\n\u001b[1;32m   1029\u001b[0m input_guardrail_results\u001b[38;5;241m.\u001b[39mextend(sequential_results)\n\u001b[1;32m   1030\u001b[0m input_guardrail_results\u001b[38;5;241m.\u001b[39mextend(parallel_results)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/run_internal/run_loop.py:1370\u001b[0m, in \u001b[0;36mrun_single_turn\u001b[0;34m(agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, server_conversation_tracker, session, session_items_to_rewind)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m normalize_input_items_for_api(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1370\u001b[0m new_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_new_response(\n\u001b[1;32m   1371\u001b[0m     agent,\n\u001b[1;32m   1372\u001b[0m     system_prompt,\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1374\u001b[0m     output_schema,\n\u001b[1;32m   1375\u001b[0m     all_tools,\n\u001b[1;32m   1376\u001b[0m     handoffs,\n\u001b[1;32m   1377\u001b[0m     hooks,\n\u001b[1;32m   1378\u001b[0m     context_wrapper,\n\u001b[1;32m   1379\u001b[0m     run_config,\n\u001b[1;32m   1380\u001b[0m     tool_use_tracker,\n\u001b[1;32m   1381\u001b[0m     server_conversation_tracker,\n\u001b[1;32m   1382\u001b[0m     prompt_config,\n\u001b[1;32m   1383\u001b[0m     session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m   1384\u001b[0m     session_items_to_rewind\u001b[38;5;241m=\u001b[39msession_items_to_rewind,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m get_single_step_result_from_response(\n\u001b[1;32m   1388\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m   1389\u001b[0m     original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1398\u001b[0m     tool_use_tracker\u001b[38;5;241m=\u001b[39mtool_use_tracker,\n\u001b[1;32m   1399\u001b[0m )\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/run_internal/run_loop.py:1465\u001b[0m, in \u001b[0;36mget_new_response\u001b[0;34m(agent, system_prompt, input, output_schema, all_tools, handoffs, hooks, context_wrapper, run_config, tool_use_tracker, server_conversation_tracker, prompt_config, session, session_items_to_rewind)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo conversation_id available for request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m     new_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m model\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[1;32m   1466\u001b[0m         system_instructions\u001b[38;5;241m=\u001b[39mfiltered\u001b[38;5;241m.\u001b[39minstructions,\n\u001b[1;32m   1467\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mfiltered\u001b[38;5;241m.\u001b[39minput,\n\u001b[1;32m   1468\u001b[0m         model_settings\u001b[38;5;241m=\u001b[39mmodel_settings,\n\u001b[1;32m   1469\u001b[0m         tools\u001b[38;5;241m=\u001b[39mall_tools,\n\u001b[1;32m   1470\u001b[0m         output_schema\u001b[38;5;241m=\u001b[39moutput_schema,\n\u001b[1;32m   1471\u001b[0m         handoffs\u001b[38;5;241m=\u001b[39mhandoffs,\n\u001b[1;32m   1472\u001b[0m         tracing\u001b[38;5;241m=\u001b[39mget_model_tracing_impl(\n\u001b[1;32m   1473\u001b[0m             run_config\u001b[38;5;241m.\u001b[39mtracing_disabled, run_config\u001b[38;5;241m.\u001b[39mtrace_include_sensitive_data\n\u001b[1;32m   1474\u001b[0m         ),\n\u001b[1;32m   1475\u001b[0m         previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m   1476\u001b[0m         conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m   1477\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt_config,\n\u001b[1;32m   1478\u001b[0m     )\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BadRequestError\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/models/openai_responses.py:98\u001b[0m, in \u001b[0;36mOpenAIResponsesModel.get_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, conversation_id, prompt)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled\u001b[38;5;241m=\u001b[39mtracing\u001b[38;5;241m.\u001b[39mis_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_response(\n\u001b[1;32m     99\u001b[0m             system_instructions,\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    101\u001b[0m             model_settings,\n\u001b[1;32m    102\u001b[0m             tools,\n\u001b[1;32m    103\u001b[0m             output_schema,\n\u001b[1;32m    104\u001b[0m             handoffs,\n\u001b[1;32m    105\u001b[0m             previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    106\u001b[0m             conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m    107\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _debug\u001b[38;5;241m.\u001b[39mDONT_LOG_MODEL_DATA:\n\u001b[1;32m    112\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM responded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/agents/models/openai_responses.py:327\u001b[0m, in \u001b[0;36mOpenAIResponsesModel._fetch_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, conversation_id, stream, prompt)\u001b[0m\n\u001b[1;32m    323\u001b[0m         response_format \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_settings\u001b[38;5;241m.\u001b[39mverbosity}\n\u001b[1;32m    325\u001b[0m stream_param: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m|\u001b[39m Omit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m omit\n\u001b[0;32m--> 327\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    328\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(previous_response_id),\n\u001b[1;32m    329\u001b[0m     conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(conversation_id),\n\u001b[1;32m    330\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(system_instructions),\n\u001b[1;32m    331\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_param,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlist_input,\n\u001b[1;32m    333\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    334\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_param,\n\u001b[1;32m    335\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(prompt),\n\u001b[1;32m    336\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtemperature),\n\u001b[1;32m    337\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtop_p),\n\u001b[1;32m    338\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtruncation),\n\u001b[1;32m    339\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mmax_tokens),\n\u001b[1;32m    340\u001b[0m     tool_choice\u001b[38;5;241m=\u001b[39mtool_choice_param,\n\u001b[1;32m    341\u001b[0m     parallel_tool_calls\u001b[38;5;241m=\u001b[39mparallel_tool_calls,\n\u001b[1;32m    342\u001b[0m     stream\u001b[38;5;241m=\u001b[39mcast(Any, stream_param),\n\u001b[1;32m    343\u001b[0m     extra_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_headers(model_settings),\n\u001b[1;32m    344\u001b[0m     extra_query\u001b[38;5;241m=\u001b[39mmodel_settings\u001b[38;5;241m.\u001b[39mextra_query,\n\u001b[1;32m    345\u001b[0m     extra_body\u001b[38;5;241m=\u001b[39mmodel_settings\u001b[38;5;241m.\u001b[39mextra_body,\n\u001b[1;32m    346\u001b[0m     text\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    347\u001b[0m     store\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mstore),\n\u001b[1;32m    348\u001b[0m     prompt_cache_retention\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mprompt_cache_retention),\n\u001b[1;32m    349\u001b[0m     reasoning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mreasoning),\n\u001b[1;32m    350\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mmetadata),\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args,\n\u001b[1;32m    352\u001b[0m )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Union[Response, AsyncStream[ResponseStreamEvent]], response)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/openai/resources/responses/responses.py:2507\u001b[0m, in \u001b[0;36mAsyncResponses.create\u001b[0;34m(self, background, context_management, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2470\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   2506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response \u001b[38;5;241m|\u001b[39m AsyncStream[ResponseStreamEvent]:\n\u001b[0;32m-> 2507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   2508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/responses\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2509\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   2510\u001b[0m             {\n\u001b[1;32m   2511\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackground\u001b[39m\u001b[38;5;124m\"\u001b[39m: background,\n\u001b[1;32m   2512\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_management\u001b[39m\u001b[38;5;124m\"\u001b[39m: context_management,\n\u001b[1;32m   2513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m\"\u001b[39m: conversation,\n\u001b[1;32m   2514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m: include,\n\u001b[1;32m   2515\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2516\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[1;32m   2517\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_output_tokens,\n\u001b[1;32m   2518\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tool_calls,\n\u001b[1;32m   2519\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   2520\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   2521\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   2522\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: previous_response_id,\n\u001b[1;32m   2523\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m   2524\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   2525\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_retention\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_retention,\n\u001b[1;32m   2526\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning,\n\u001b[1;32m   2527\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   2528\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   2529\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   2530\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   2531\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   2532\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   2533\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[1;32m   2534\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   2535\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   2536\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   2537\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   2538\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncation,\n\u001b[1;32m   2539\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   2540\u001b[0m             },\n\u001b[1;32m   2541\u001b[0m             response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsStreaming\n\u001b[1;32m   2542\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   2543\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsNonStreaming,\n\u001b[1;32m   2544\u001b[0m         ),\n\u001b[1;32m   2545\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   2546\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   2547\u001b[0m         ),\n\u001b[1;32m   2548\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mResponse,\n\u001b[1;32m   2549\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2550\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ResponseStreamEvent],\n\u001b[1;32m   2551\u001b[0m     )\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/openai/_base_client.py:1884\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, content, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1875\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1876\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1877\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1878\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1879\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1880\u001b[0m     )\n\u001b[1;32m   1881\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1882\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, content\u001b[38;5;241m=\u001b[39mcontent, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1883\u001b[0m )\n\u001b[0;32m-> 1884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
            "File \u001b[0;32m~/cpp_chatsystem/venv/lib/python3.9/site-packages/openai/_base_client.py:1622\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1624\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mAPITimeoutError\u001b[0m: Request timed out."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "[non-fatal] Tracing: max retries reached, giving up on this batch.\n",
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "[non-fatal] Tracing: request failed: [Errno 101] Network is unreachable\n",
            "[non-fatal] Tracing: max retries reached, giving up on this batch.\n"
          ]
        }
      ],
      "source": [
        "with trace(workflow_name=\"Handoff message filter\"):\n",
        "    # Step 1: 发送第一条消息\n",
        "    result = await Runner.run(first_agent, input=\"Hi, my name is Sora.\")  # type: ignore[top-level-await]\n",
        "    print(\"Step 1 done\")\n",
        "\n",
        "    # Step 2: 请求生成随机数\n",
        "    result = await Runner.run(\n",
        "        first_agent,\n",
        "        input=result.to_input_list()\n",
        "        + [{\"content\": \"Can you generate a random number between 0 and 100?\", \"role\": \"user\"}],\n",
        "    )\n",
        "    print(\"Step 2 done\")\n",
        "\n",
        "    # Step 3: 切换到 second_agent\n",
        "    result = await Runner.run(\n",
        "        second_agent,\n",
        "        input=result.to_input_list()\n",
        "        + [\n",
        "            {\n",
        "                \"content\": \"I live in New York City. Whats the population of the city?\",\n",
        "                \"role\": \"user\",\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    print(\"Step 3 done\")\n",
        "\n",
        "    # Step 4: 触发 handoff（用户说西班牙语）\n",
        "    result = await Runner.run(\n",
        "        second_agent,\n",
        "        input=result.to_input_list()\n",
        "        + [\n",
        "            {\n",
        "                \"content\": \"Por favor habla en español. ¿Cuál es mi nombre y dónde vivo?\",\n",
        "                \"role\": \"user\",\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    print(\"Step 4 done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 查看最终消息\n",
        "\n",
        "由于 input_filter 生效，Spanish Assistant 收到的历史已过滤：前两条消息被移除，工具调用也被移除。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Final messages ===\\n\")\n",
        "for item in result.to_input_list():\n",
        "    print(json.dumps(item, indent=2, ensure_ascii=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
